{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Embedding, TextVectorization\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verifying GPU Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print(physical_devices)\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfCeT6h5CL-E"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "train_data = data[:int(0.8*159571)]\n",
        "test_data = data[int(0.8*159571):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[train_data[\"threat\"]==1][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.hist([len(i) for i in train_data[\"comment_text\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "column_labels = train_data.columns.tolist()[2:]\n",
        "label_counts = train_data[column_labels].sum().sort_values()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "ax = sns.barplot(x=label_counts.values,\n",
        "\t\t\t\ty=label_counts.index, palette='viridis')\n",
        "\n",
        "plt.xlabel('Number of Occurrences')\n",
        "plt.ylabel('Labels')\n",
        "plt.title('Distribution of Label Occurrences')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_toxic = train_data[train_data[column_labels].sum(axis=1) > 0]\n",
        "train_clean = train_data[train_data[column_labels].sum(axis=1) == 0]\n",
        "\n",
        "num_toxic = len(train_toxic)\n",
        "num_clean = len(train_clean)\n",
        "\n",
        "plot_data = pd.DataFrame(\n",
        "\t{'Category': ['Toxic', 'Clean'], 'Count': [num_toxic, num_clean]})\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "ax = sns.barplot(x='Count', y='Category', data=plot_data, palette='viridis')\n",
        "\n",
        "plt.xlabel('Number of Comments')\n",
        "plt.ylabel('Category')\n",
        "plt.title('Distribution of Toxic and Clean Comments')\n",
        "\n",
        "ax.tick_params()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 10))\n",
        "\n",
        "labels_list = ['toxic', 'severe_toxic', 'obscene',\n",
        "\t\t\t\t'threat', 'insult', 'identity_hate']\n",
        "plt.title('Correlation of Toxicity Criteria with Each Other')\n",
        "\n",
        "sns.heatmap(train_data[labels_list].corr(),cmap='rocket_r', annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_toxic_undersample = train_data[train_data['toxic'] == 0].sample(n=(train_data['toxic'] == 1).sum(), random_state=201)\n",
        "non_toxic_undersample\n",
        "train_data = pd.concat([train_data[train_data['toxic'] == 1], non_toxic_undersample])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_toxic = train_data[train_data[column_labels].sum(axis=1) > 0]\n",
        "train_clean = train_data[train_data[column_labels].sum(axis=1) == 0]\n",
        "\n",
        "num_toxic = len(train_toxic)\n",
        "num_clean = len(train_clean)\n",
        "\n",
        "plot_data = pd.DataFrame(\n",
        "\t{'Category': ['Toxic', 'Clean'], 'Count': [num_toxic, num_clean]})\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "ax = sns.barplot(x='Count', y='Category', data=plot_data, palette='viridis')\n",
        "\n",
        "plt.xlabel('Number of Comments')\n",
        "plt.ylabel('Category')\n",
        "plt.title('Distribution of Toxic and Clean Comments')\n",
        "\n",
        "ax.tick_params()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkcF3xzSKU2x"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KQ1VgJgKfig",
        "outputId": "2d690bbf-7f41-46de-ec05-78e4728c9b57"
      },
      "outputs": [],
      "source": [
        "x_train = train_data[\"comment_text\"]\n",
        "y_train = train_data[train_data.columns[2:]].values\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test = test_data[\"comment_text\"]\n",
        "y_test = test_data[test_data.columns[2:]].values\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvntZZsYK9pA"
      },
      "outputs": [],
      "source": [
        "MAX_FEATURES = 200000 #Number of words in vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La97hu_GLHzm"
      },
      "outputs": [],
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLs0bR4VMN6Z"
      },
      "outputs": [],
      "source": [
        "vectorizer.adapt(x_train.values)\n",
        "vectorized_train_text = vectorizer(x_train.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer.adapt(x_test.values)\n",
        "vectorized_test_text = vectorizer(x_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLEy0o6YMlY6",
        "outputId": "36c2642f-27e7-4e11-aa64-73aa1bb5e4e6"
      },
      "outputs": [],
      "source": [
        "#MCSHBAP: map, cache, shuffle, batch, prefetch\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((vectorized_train_text,y_train))\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(160000)\n",
        "train_dataset = train_dataset.batch(32)\n",
        "train_dataset = train_dataset.prefetch(8) #Prevents bottleneck\n",
        "train_dataset.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#MCSHBAP: map, cache, shuffle, batch, prefetch\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((vectorized_test_text,y_test))\n",
        "test_dataset = test_dataset.cache()\n",
        "test_dataset = test_dataset.shuffle(160000)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.prefetch(8) #Prevents bottleneck\n",
        "test_dataset.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXTh8rjR0Bbp",
        "outputId": "ad06278f-96d6-4213-cd0d-b6016b249823"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch = train_dataset.as_numpy_iterator().next()\n",
        "x_batch.shape,y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-UZ_DEJ03Xy"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch = test_dataset.as_numpy_iterator().next()\n",
        "x_batch.shape,y_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehc_mnP1qYmi"
      },
      "source": [
        "### Model Creation (Bidirectional LSTM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bE5PnMI2RXK"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_FEATURES+1, 32))\n",
        "model.add(Bidirectional(LSTM(32, activation = \"tanh\")))\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(6, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRMr8Ze0_w1j",
        "outputId": "ac706eea-4ef1-4579-9c45-aa7e85904d11"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxT59S5wDHSO"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "               optimizer=\"adam\",\n",
        "               metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AcDR2FLHDXZW",
        "outputId": "eb244aa4-1ad7-42ff-9a1f-362656bce924"
      },
      "outputs": [],
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",patience=3)\n",
        "model_history = model.fit(x = train_dataset,\n",
        "                            epochs=10,\n",
        "                            validation_data=test_dataset,\n",
        "                          callbacks = [stop_early]\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(model_history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(model_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(model_history.history['loss'], label='Loss')\n",
        "plt.plot(model_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtGM7vQ0DrTS"
      },
      "outputs": [],
      "source": [
        "model.save(\"LSTM-Model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfNWvfX1q_6Y"
      },
      "source": [
        "### Using the model to predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(val)\n",
        "y_pred = (y_pred>0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = []\n",
        "for i in test_dataset.as_numpy_iterator():\n",
        "    for j in i[1]:\n",
        "        y_true += [j]\n",
        "y_true = np.array(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_y_pred = []\n",
        "for i in y_pred:\n",
        "    cm_y_pred += [i[0]]\n",
        "cm_y_pred = np.array(cm_y_pred)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_y_true = []\n",
        "for i in y_true:\n",
        "    cm_y_true += [i[0]]\n",
        "cm_y_true = np.array(cm_y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(cm_y_true,cm_y_pred)\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix,display_labels=[\"Not Toxic\",\"Toxic\"])\n",
        "cm_display.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_FEATURES = 200000\n",
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"train.csv\")\n",
        "x = train_data[\"comment_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer.adapt(x.values)\n",
        "vectorized_text = vectorizer(x.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y78sgx5zcat3"
      },
      "outputs": [],
      "source": [
        "model1 = tf.keras.models.load_model('LSTM-Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIGipq48cvFX"
      },
      "outputs": [],
      "source": [
        "input_text = vectorizer(\"Fuck your nigger ass\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoWqTluNdjp8",
        "outputId": "502d4a7b-785e-4f46-dc74-076d809f4803"
      },
      "outputs": [],
      "source": [
        "res = model1.predict(np.expand_dims(input_text,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHw44JqTe6Nj"
      },
      "outputs": [],
      "source": [
        "output = (res>0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjqu7Beee_Fw",
        "outputId": "d343f13b-ff95-4fee-d05a-671e3c634573"
      },
      "outputs": [],
      "source": [
        "col = train_data.columns[2:]\n",
        "col = col.to_numpy()\n",
        "col.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJGEhF5GiZYE",
        "outputId": "bb0f2151-bf8e-4f91-abe2-4f626e6c4559"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for index,element in np.ndenumerate(output):\n",
        "  if(element==1):\n",
        "    count = count+1\n",
        "    _,k = index\n",
        "    print(col[k])\n",
        "if(count==0):\n",
        "  print(\"Not Toxic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "column_labels = data.columns.tolist()[2:]\n",
        "label_counts = data[column_labels].sum().sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_toxic = data[data[column_labels].sum(axis=1) > 0]\n",
        "train_clean = data[data[column_labels].sum(axis=1) == 0]\n",
        "\n",
        "num_toxic = len(train_toxic)\n",
        "num_clean = len(train_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_clean_sampled = train_clean.sample(n=16225, random_state=42)\n",
        "dataframe = pd.concat([train_toxic, train_clean_sampled], axis=0)\n",
        "dataframe = dataframe.sample(frac=1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "\tdataframe['comment_text'], dataframe.iloc[:, 2:], test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_texts, val_texts, test_labels, val_labels = train_test_split(\n",
        "\ttest_texts, test_labels, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_and_encode(tokenizer, comments, labels, max_length=128):\n",
        "\tinput_ids = []\n",
        "\tattention_masks = []\n",
        "\tfor comment in comments:\n",
        "\t\tencoded_dict = tokenizer.encode_plus(\n",
        "\t\t\tcomment,\n",
        "\t\t\tadd_special_tokens=False,\n",
        "\t\t\tmax_length=max_length,\n",
        "\t\t\tpad_to_max_length=True,\n",
        "\t\t\treturn_attention_mask=True,\n",
        "\t\t\treturn_tensors='pt'\n",
        "\t\t)\n",
        "\t\tinput_ids.append(encoded_dict['input_ids'])\n",
        "\t\tattention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\tinput_ids = torch.cat(input_ids, dim=0)\n",
        "\tattention_masks = torch.cat(attention_masks, dim=0)\n",
        "\tlabels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "\treturn input_ids, attention_masks, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids, attention_masks, labels = tokenize_and_encode(\n",
        "\ttokenizer,\n",
        "\ttrain_texts,\n",
        "\ttrain_labels.values\n",
        ")\n",
        "test_input_ids, test_attention_masks, test_labels = tokenize_and_encode(\n",
        "\ttokenizer,\n",
        "\ttest_texts,\n",
        "\ttest_labels.values\n",
        ")\n",
        "val_input_ids, val_attention_masks, val_labels = tokenize_and_encode(\n",
        "\ttokenizer,\n",
        "\tval_texts,\n",
        "\tval_labels.values\n",
        ")\n",
        "\n",
        "print('Training Comments :',train_texts.shape)\n",
        "print('Input Ids\t\t :',input_ids.shape)\n",
        "print('Attention Mask :',attention_masks.shape)\n",
        "print('Labels\t\t :',labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, optimizer, device, num_epochs):\n",
        "\n",
        "\tloss_line = []\n",
        "\tval_loss_line = []\n",
        "\n",
        "\tfor epoch in range(num_epochs):\n",
        "\n",
        "\t\tmodel.train()\n",
        "\t\ttotal_loss = 0\n",
        "\n",
        "\t\tfor batch in train_loader:\n",
        "\t\t\tinput_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
        "\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\t\toutputs = model(\n",
        "\t\t\t\tinput_ids, attention_mask=attention_mask, labels=labels)\n",
        "\t\t\tloss = outputs.loss\n",
        "\t\t\ttotal_loss += loss.item()\n",
        "\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\n",
        "\t\tmodel.eval() \n",
        "\n",
        "\t\tval_loss = 0\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tfor batch in val_loader:\n",
        "\t\t\t\tinput_ids, attention_mask, labels = [\n",
        "\t\t\t\t\tt.to(device) for t in batch]\n",
        "\n",
        "\t\t\t\toutputs = model(\n",
        "\t\t\t\t\tinput_ids, attention_mask=attention_mask, labels=labels)\n",
        "\t\t\t\tloss = outputs.loss\n",
        "\t\t\t\tval_loss += loss.item()\n",
        "\t\tprint(f'Epoch {epoch+1}, Training Loss: {total_loss/len(train_loader)},Validation loss:{val_loss/len(val_loader)}')\n",
        "\t\tloss_line += [total_loss/len(train_loader)]\n",
        "\t\tval_loss_line += [val_loss/len(val_loader)]\n",
        "\t\n",
        "\tplt.figure(figsize=(10, 6))\n",
        "\tplt.plot(loss_line, label='Loss')\n",
        "\tplt.plot(val_loss_line, label='Validation Loss')\n",
        "\tplt.title('Model Loss')\n",
        "\tplt.xlabel('Epoch')\n",
        "\tplt.ylabel('Loss')\n",
        "\tplt.legend()\n",
        "\tplt.grid(True)\n",
        "\tplt.show()\n",
        "\n",
        "train_model(model, train_loader, optimizer, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "\tmodel.eval()\n",
        "\n",
        "\ttrue_labels = []\n",
        "\tpredicted_probs = []\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\tfor batch in test_loader:\n",
        "\t\t\tinput_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
        "\n",
        "\t\t\toutputs = model(input_ids, attention_mask=attention_mask)\n",
        "\t\t\tpredicted_probs_batch = torch.sigmoid(outputs.logits)\n",
        "\t\t\tpredicted_probs.append(predicted_probs_batch.cpu().numpy())\n",
        "\n",
        "\t\t\ttrue_labels_batch = labels.cpu().numpy()\n",
        "\t\t\ttrue_labels.append(true_labels_batch)\n",
        "\n",
        "\ttrue_labels = np.concatenate(true_labels, axis=0)\n",
        "\tpredicted_probs = np.concatenate(predicted_probs, axis=0)\n",
        "\tpredicted_labels = (predicted_probs > 0.5).astype(int) \n",
        "\n",
        "\taccuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\tprecision = precision_score(true_labels, predicted_labels, average='micro')\n",
        "\trecall = recall_score(true_labels, predicted_labels, average='micro')\n",
        "\n",
        "\tprint(f'Accuracy: {accuracy:.4f}')\n",
        "\tprint(f'Precision: {precision:.4f}')\n",
        "\tprint(f'Recall: {recall:.4f}')\n",
        "\n",
        "evaluate_model(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = \"BERT-Model\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction using BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model_name = \"BERT-Model\"\n",
        "Bert_Tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "Bert_Model = BertForSequenceClassification.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_user_input(input_text, model=Bert_Model, tokenizer=Bert_Tokenizer, device=device):\n",
        "\tuser_input = [input_text]\n",
        "\n",
        "\tuser_encodings = tokenizer(\n",
        "\t\tuser_input, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "\tuser_dataset = TensorDataset(\n",
        "\t\tuser_encodings['input_ids'], user_encodings['attention_mask'])\n",
        "\n",
        "\tuser_loader = DataLoader(user_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "\tmodel.eval()\n",
        "\twith torch.no_grad():\n",
        "\t\tfor batch in user_loader:\n",
        "\t\t\tinput_ids, attention_mask = [t.to(device) for t in batch]\n",
        "\t\t\toutputs = model(input_ids, attention_mask=attention_mask)\n",
        "\t\t\tlogits = outputs.logits\n",
        "\t\t\tpredictions = torch.sigmoid(logits)\n",
        "\n",
        "\tpredicted_labels = (predictions.cpu().numpy() > 0.5).astype(int)\n",
        "\tlabels_list = ['toxic', 'severe_toxic', 'obscene',\n",
        "\t\t\t\t'threat', 'insult', 'identity_hate']\n",
        "\tresult = dict(zip(labels_list, predicted_labels[0]))\n",
        "\treturn result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict_user_input(input_text=\"Your mother\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AOvUZ3JXBfwj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-04 01:19:50.493207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-04 01:19:53.620388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-04 01:19:56.387577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-04 01:19:56.736310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-04 01:19:56.736473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gfCeT6h5CL-E"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "WsSCluW7CYmh",
        "outputId": "2084ab5b-b7d6-445a-ee2d-d54aa6c3ffda"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>001810bf8c45bf5f</td>\n",
              "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>00190820581d90ce</td>\n",
              "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0020e7119b96eeeb</td>\n",
              "      <td>Stupid peace of shit stop deleting my stuff as...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0020fd96ed3b8c8b</td>\n",
              "      <td>=Tony Sidaway is obviously a fistfuckee. He lo...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159494</th>\n",
              "      <td>fef4cf7ba0012866</td>\n",
              "      <td>\"\\n\\n our previous conversation \\n\\nyou fuckin...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159514</th>\n",
              "      <td>ff39a2895fc3b40e</td>\n",
              "      <td>YOU ARE A MISCHIEVIOUS PUBIC HAIR</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159541</th>\n",
              "      <td>ffa33d3122b599d6</td>\n",
              "      <td>Your absurd edits \\n\\nYour absurd edits on gre...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159546</th>\n",
              "      <td>ffb47123b2d82762</td>\n",
              "      <td>\"\\n\\nHey listen don't you ever!!!! Delete my e...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159554</th>\n",
              "      <td>ffbdbb0483ed0841</td>\n",
              "      <td>and i'm going to keep posting the stuff u dele...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7877 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id                                       comment_text  \\\n",
              "6       0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
              "42      001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
              "43      00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
              "55      0020e7119b96eeeb  Stupid peace of shit stop deleting my stuff as...   \n",
              "56      0020fd96ed3b8c8b  =Tony Sidaway is obviously a fistfuckee. He lo...   \n",
              "...                  ...                                                ...   \n",
              "159494  fef4cf7ba0012866  \"\\n\\n our previous conversation \\n\\nyou fuckin...   \n",
              "159514  ff39a2895fc3b40e                  YOU ARE A MISCHIEVIOUS PUBIC HAIR   \n",
              "159541  ffa33d3122b599d6  Your absurd edits \\n\\nYour absurd edits on gre...   \n",
              "159546  ffb47123b2d82762  \"\\n\\nHey listen don't you ever!!!! Delete my e...   \n",
              "159554  ffbdbb0483ed0841  and i'm going to keep posting the stuff u dele...   \n",
              "\n",
              "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
              "6           1             1        1       0       1              0  \n",
              "42          1             0        1       0       1              1  \n",
              "43          1             0        1       0       1              0  \n",
              "55          1             1        1       0       1              0  \n",
              "56          1             0        1       0       1              0  \n",
              "...       ...           ...      ...     ...     ...            ...  \n",
              "159494      1             0        1       0       1              1  \n",
              "159514      1             0        0       0       1              0  \n",
              "159541      1             0        1       0       1              0  \n",
              "159546      1             0        0       0       1              0  \n",
              "159554      1             0        1       0       1              0  \n",
              "\n",
              "[7877 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[train_data[\"insult\"]==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPmkoAJIt1Aa",
        "outputId": "e3db9d5f-ed14-4211-ae99-12cb7f22b00a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "176    I think that your a Fagget get a oife and burn...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[train_data[\"id\"] == \"006b94add72ed61c\"][\"comment_text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkcF3xzSKU2x"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gunM2nd1Fn2f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization ##This will hwlp in tokeinizing the sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KQ1VgJgKfig",
        "outputId": "2d690bbf-7f41-46de-ec05-78e4728c9b57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = train_data[\"comment_text\"]\n",
        "y = train_data[train_data.columns[2:]].values\n",
        "\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LvntZZsYK9pA"
      },
      "outputs": [],
      "source": [
        "MAX_FEATURES = 200000 #Number of words in vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "La97hu_GLHzm"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-04 01:19:59.121451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-04 01:19:59.121618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-04 01:19:59.121733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-04 01:19:59.173527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-04 01:19:59.173720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-04 01:19:59.173855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-04 01:19:59.173965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2449 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nLs0bR4VMN6Z"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-04 01:20:06.381586: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 169146912 exceeds 10% of free system memory.\n",
            "2023-08-04 01:20:06.381655: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 253720368 exceeds 10% of free system memory.\n",
            "2023-08-04 01:20:06.722927: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 84573456 exceeds 10% of free system memory.\n",
            "2023-08-04 01:20:06.767076: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 42286728 exceeds 10% of free system memory.\n",
            "2023-08-04 01:20:06.823807: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 84573456 exceeds 10% of free system memory.\n"
          ]
        }
      ],
      "source": [
        "vectorizer.adapt(x.values)\n",
        "\n",
        "vectorized_text = vectorizer(x.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLEy0o6YMlY6",
        "outputId": "36c2642f-27e7-4e11-aa64-73aa1bb5e4e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 1269,    86,  1540, ...,     0,     0,     0],\n",
              "        [17003, 28539,   756, ...,     0,     0,     0],\n",
              "        [  397,    12,   762, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  187,   118,    13, ...,     0,     0,     0],\n",
              "        [ 4428,     9,   219, ...,     0,     0,     0],\n",
              "        [ 3340,    16,     2, ...,     0,     0,     0]]),\n",
              " array([[0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 1, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0]]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#MCSHBAP: map, cache, shuffle, batch, prefetch\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text,y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(32)\n",
        "dataset = dataset.prefetch(8)#Prevents bottleneck\n",
        "dataset.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXTh8rjR0Bbp",
        "outputId": "ad06278f-96d6-4213-cd0d-b6016b249823"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((32, 1800), (32, 6))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_batch, y_batch = dataset.as_numpy_iterator().next()\n",
        "x_batch.shape,y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u-UZ_DEJ03Xy"
      },
      "outputs": [],
      "source": [
        "train = dataset.take(int(len(dataset)*0.8)+1)\n",
        "val = dataset.skip(int(len(dataset)*0.8)+1).take(int(len(dataset)*0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehc_mnP1qYmi"
      },
      "source": [
        "##Creating a model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fgDRJVK-1dod"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-bE5PnMI2RXK"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_FEATURES+1, 32))\n",
        "model.add(Bidirectional(LSTM(32, activation = \"tanh\")))\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(6, activation=\"sigmoid\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRMr8Ze0_w1j",
        "outputId": "ac706eea-4ef1-4579-9c45-aa7e85904d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          6400032   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                16640     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16640     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6466982 (24.67 MB)\n",
            "Trainable params: 6466982 (24.67 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vxT59S5wDHSO"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "               optimizer=\"adam\",\n",
        "               metrics=[\"accuracy\"])\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",patience=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AcDR2FLHDXZW",
        "outputId": "eb244aa4-1ad7-42ff-9a1f-362656bce924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-04 01:20:31.395246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
            "2023-08-04 01:20:32.393086: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1b98bcba70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-08-04 01:20:32.393137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
            "2023-08-04 01:20:33.484695: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-08-04 01:20:35.429309: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:543] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
            "Searched for CUDA in the following directories:\n",
            "  ./cuda_sdk_lib\n",
            "  /usr/local/cuda-11.8\n",
            "  /usr/local/cuda\n",
            "  .\n",
            "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
            "2023-08-04 01:20:37.306579: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3990/3990 [==============================] - 492s 120ms/step - loss: 0.0633 - accuracy: 0.9803 - val_loss: 0.0437 - val_accuracy: 0.9947\n",
            "Epoch 2/10\n",
            "3990/3990 [==============================] - 388s 97ms/step - loss: 0.0445 - accuracy: 0.9686 - val_loss: 0.0393 - val_accuracy: 0.9893\n",
            "Epoch 3/10\n",
            "3990/3990 [==============================] - 383s 96ms/step - loss: 0.0391 - accuracy: 0.9767 - val_loss: 0.0339 - val_accuracy: 0.9942\n",
            "Epoch 4/10\n",
            "3990/3990 [==============================] - 377s 94ms/step - loss: 0.0340 - accuracy: 0.9780 - val_loss: 0.0298 - val_accuracy: 0.9941\n"
          ]
        }
      ],
      "source": [
        "model_history = model.fit(x = train,\n",
        "                            epochs=10,\n",
        "                            validation_data=val,\n",
        "                          callbacks = [stop_early]\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MtGM7vQ0DrTS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/assets\n"
          ]
        }
      ],
      "source": [
        "model.save(\"models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfNWvfX1q_6Y"
      },
      "source": [
        "##Using the model to predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "y78sgx5zcat3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model1 = tf.keras.models.load_model('models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dIGipq48cvFX"
      },
      "outputs": [],
      "source": [
        "input_text = vectorizer(\"Ramesh is a gay faggot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoWqTluNdjp8",
        "outputId": "502d4a7b-785e-4f46-dc74-076d809f4803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 846ms/step\n"
          ]
        }
      ],
      "source": [
        "res = model1.predict(np.expand_dims(input_text,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jHw44JqTe6Nj"
      },
      "outputs": [],
      "source": [
        "output = (res>0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjqu7Beee_Fw",
        "outputId": "d343f13b-ff95-4fee-d05a-671e3c634573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col = train_data.columns[2:]\n",
        "col = col.to_numpy()\n",
        "col.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJGEhF5GiZYE",
        "outputId": "bb0f2151-bf8e-4f91-abe2-4f626e6c4559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toxic\n",
            "obscene\n",
            "insult\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for index,element in np.ndenumerate(output):\n",
        "  if(element==1):\n",
        "    count = count+1\n",
        "    _,k = index\n",
        "    print(col[k])\n",
        "if(count==0):\n",
        "  print(\"Not Toxic\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
